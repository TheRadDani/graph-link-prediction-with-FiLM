{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOgtUk+XutX0ifkDb/9xR6m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheRadDani/graph-link-prediction-with-FiLM/blob/main/FiLM_for_link_prediction_on_graphs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kB71tQCk3Oy",
        "outputId": "96446440-c283-405b-9704-9266cf254239"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.5.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.9.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.7.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "69K01KyNkN8h"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from torch_geometric.datasets import PPI\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import FiLMConv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = os.path.join(os.getcwd(), 'data', 'PPI')\n",
        "train_dataset = PPI(path, split='train')\n",
        "val_dataset = PPI(path, split='val')\n",
        "test_dataset = PPI(path, split='test')\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=2, shuffle=False)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=2, shuffle=False)"
      ],
      "metadata": {
        "id": "nIKD8SqemUqc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Network(torch.nn.Module):\n",
        "  def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
        "               dropout=0.0):\n",
        "    super(Network, self).__init__()\n",
        "\n",
        "    self.dropout = dropout\n",
        "    self.convs = nn.ModuleList()\n",
        "    self.convs.append(FiLMConv(in_channels, hidden_channels))\n",
        "    for _ in range(num_layers - 2):\n",
        "      self.convs.append(FiLMConv(hidden_channels, hidden_channels))\n",
        "    self.convs.append(FiLMConv(hidden_channels, out_channels, act=None))\n",
        "\n",
        "    self.norms = nn.ModuleList()\n",
        "    for _ in range(num_layers - 1):\n",
        "      self.norms.append(nn.LayerNorm(hidden_channels))\n",
        "\n",
        "  def forward(self, x, edge_index):\n",
        "    for conv, norm in zip(self.convs[:-1], self.norms):\n",
        "      x = norm(conv(x, edge_index))\n",
        "      x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "    x = self.convs[-1](x, edge_index)\n",
        "    return x"
      ],
      "metadata": {
        "id": "Lc8KNTtRnHOa"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = Network(in_channels=train_dataset.num_features,hidden_channels=320,\n",
        "                out_channels=train_dataset.num_classes, num_layers = 4,\n",
        "                dropout=0.1).to(device)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "zLixnaBPo1ME"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_dataloader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M28uOjPFqrDl",
        "outputId": "fc2c2c19-e02e-4114-d335-6328d2cbccbb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataBatch(x=[4561, 50], edge_index=[2, 117636], y=[4561, 121], batch=[4561], ptr=[3])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train():\n",
        "  model.train()\n",
        "  total_loss = 0\n",
        "\n",
        "  for data in train_dataloader:\n",
        "    data = data.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    loss= criterion(model(data.x, data.edge_index), data.y)\n",
        "    total_loss += loss.item() * data.num_graphs\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  return total_loss / len(train_dataloader.dataset)\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(loader):\n",
        "  model.eval()\n",
        "  ys, preds = list(), list()\n",
        "  for data in loader:\n",
        "    data = data.to(device)\n",
        "    ys.append(data.y)\n",
        "    out = model(data.x, data.edge_index)\n",
        "    preds.append((out > 0).float())\n",
        "  y , pred = torch.cat(ys, dim=0).cpu().numpy(), torch.cat(preds, dim=0).cpu().numpy()\n",
        "  return f1_score(y, pred, average='micro') if pred.sum() > 0 else 0"
      ],
      "metadata": {
        "id": "wRNZURvQqXoK"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(500):\n",
        "  loss = train()\n",
        "  val_f1 = test(val_dataloader)\n",
        "  test_f1 = test(test_dataloader)\n",
        "  print(f'Epoch: {epoch+1}, Loss: {loss:.4f}, \\\n",
        "   Val F1: {val_f1:.4f}, Test F1: {test_f1:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOAeHjFfx5lC",
        "outputId": "c7cc0ac6-81ca-4d41-8f2a-8601da2c2288"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 0.0077,    Val F1: 0.9870, Test F1: 0.9926\n",
            "Epoch: 2, Loss: 0.0079,    Val F1: 0.9870, Test F1: 0.9925\n",
            "Epoch: 3, Loss: 0.0082,    Val F1: 0.9869, Test F1: 0.9926\n",
            "Epoch: 4, Loss: 0.0085,    Val F1: 0.9870, Test F1: 0.9925\n",
            "Epoch: 5, Loss: 0.0081,    Val F1: 0.9869, Test F1: 0.9925\n",
            "Epoch: 6, Loss: 0.0081,    Val F1: 0.9869, Test F1: 0.9925\n",
            "Epoch: 7, Loss: 0.0087,    Val F1: 0.9869, Test F1: 0.9923\n",
            "Epoch: 8, Loss: 0.0085,    Val F1: 0.9867, Test F1: 0.9922\n",
            "Epoch: 9, Loss: 0.0084,    Val F1: 0.9871, Test F1: 0.9925\n",
            "Epoch: 10, Loss: 0.0087,    Val F1: 0.9870, Test F1: 0.9925\n",
            "Epoch: 11, Loss: 0.0085,    Val F1: 0.9871, Test F1: 0.9925\n",
            "Epoch: 12, Loss: 0.0090,    Val F1: 0.9868, Test F1: 0.9925\n",
            "Epoch: 13, Loss: 0.0089,    Val F1: 0.9870, Test F1: 0.9923\n",
            "Epoch: 14, Loss: 0.0086,    Val F1: 0.9869, Test F1: 0.9923\n",
            "Epoch: 15, Loss: 0.0081,    Val F1: 0.9871, Test F1: 0.9925\n",
            "Epoch: 16, Loss: 0.0080,    Val F1: 0.9872, Test F1: 0.9924\n",
            "Epoch: 17, Loss: 0.0081,    Val F1: 0.9870, Test F1: 0.9925\n",
            "Epoch: 18, Loss: 0.0086,    Val F1: 0.9872, Test F1: 0.9925\n",
            "Epoch: 19, Loss: 0.0091,    Val F1: 0.9869, Test F1: 0.9925\n",
            "Epoch: 20, Loss: 0.0088,    Val F1: 0.9870, Test F1: 0.9926\n",
            "Epoch: 21, Loss: 0.0084,    Val F1: 0.9870, Test F1: 0.9926\n",
            "Epoch: 22, Loss: 0.0085,    Val F1: 0.9871, Test F1: 0.9925\n",
            "Epoch: 23, Loss: 0.0089,    Val F1: 0.9872, Test F1: 0.9926\n",
            "Epoch: 24, Loss: 0.0087,    Val F1: 0.9871, Test F1: 0.9925\n",
            "Epoch: 25, Loss: 0.0082,    Val F1: 0.9874, Test F1: 0.9925\n",
            "Epoch: 26, Loss: 0.0083,    Val F1: 0.9872, Test F1: 0.9925\n",
            "Epoch: 27, Loss: 0.0083,    Val F1: 0.9872, Test F1: 0.9926\n",
            "Epoch: 28, Loss: 0.0078,    Val F1: 0.9871, Test F1: 0.9926\n",
            "Epoch: 29, Loss: 0.0081,    Val F1: 0.9871, Test F1: 0.9926\n",
            "Epoch: 30, Loss: 0.0079,    Val F1: 0.9872, Test F1: 0.9926\n",
            "Epoch: 31, Loss: 0.0079,    Val F1: 0.9873, Test F1: 0.9926\n",
            "Epoch: 32, Loss: 0.0082,    Val F1: 0.9873, Test F1: 0.9925\n",
            "Epoch: 33, Loss: 0.0081,    Val F1: 0.9872, Test F1: 0.9925\n",
            "Epoch: 34, Loss: 0.0077,    Val F1: 0.9871, Test F1: 0.9923\n",
            "Epoch: 35, Loss: 0.0084,    Val F1: 0.9869, Test F1: 0.9924\n",
            "Epoch: 36, Loss: 0.0080,    Val F1: 0.9872, Test F1: 0.9923\n",
            "Epoch: 37, Loss: 0.0081,    Val F1: 0.9871, Test F1: 0.9925\n",
            "Epoch: 38, Loss: 0.0080,    Val F1: 0.9874, Test F1: 0.9927\n",
            "Epoch: 39, Loss: 0.0078,    Val F1: 0.9872, Test F1: 0.9924\n",
            "Epoch: 40, Loss: 0.0081,    Val F1: 0.9875, Test F1: 0.9926\n",
            "Epoch: 41, Loss: 0.0081,    Val F1: 0.9875, Test F1: 0.9926\n",
            "Epoch: 42, Loss: 0.0080,    Val F1: 0.9876, Test F1: 0.9927\n",
            "Epoch: 43, Loss: 0.0076,    Val F1: 0.9872, Test F1: 0.9926\n",
            "Epoch: 44, Loss: 0.0080,    Val F1: 0.9871, Test F1: 0.9925\n",
            "Epoch: 45, Loss: 0.0075,    Val F1: 0.9873, Test F1: 0.9926\n",
            "Epoch: 46, Loss: 0.0076,    Val F1: 0.9874, Test F1: 0.9926\n",
            "Epoch: 47, Loss: 0.0075,    Val F1: 0.9877, Test F1: 0.9928\n",
            "Epoch: 48, Loss: 0.0070,    Val F1: 0.9876, Test F1: 0.9927\n",
            "Epoch: 49, Loss: 0.0069,    Val F1: 0.9875, Test F1: 0.9927\n",
            "Epoch: 50, Loss: 0.0079,    Val F1: 0.9875, Test F1: 0.9927\n",
            "Epoch: 51, Loss: 0.0073,    Val F1: 0.9876, Test F1: 0.9927\n",
            "Epoch: 52, Loss: 0.0073,    Val F1: 0.9874, Test F1: 0.9927\n",
            "Epoch: 53, Loss: 0.0076,    Val F1: 0.9872, Test F1: 0.9927\n",
            "Epoch: 54, Loss: 0.0074,    Val F1: 0.9871, Test F1: 0.9927\n",
            "Epoch: 55, Loss: 0.0074,    Val F1: 0.9872, Test F1: 0.9928\n",
            "Epoch: 56, Loss: 0.0075,    Val F1: 0.9873, Test F1: 0.9927\n",
            "Epoch: 57, Loss: 0.0074,    Val F1: 0.9874, Test F1: 0.9927\n",
            "Epoch: 58, Loss: 0.0074,    Val F1: 0.9875, Test F1: 0.9926\n",
            "Epoch: 59, Loss: 0.0073,    Val F1: 0.9872, Test F1: 0.9927\n",
            "Epoch: 60, Loss: 0.0074,    Val F1: 0.9871, Test F1: 0.9927\n",
            "Epoch: 61, Loss: 0.0076,    Val F1: 0.9871, Test F1: 0.9927\n",
            "Epoch: 62, Loss: 0.0074,    Val F1: 0.9872, Test F1: 0.9927\n",
            "Epoch: 63, Loss: 0.0074,    Val F1: 0.9872, Test F1: 0.9928\n",
            "Epoch: 64, Loss: 0.0074,    Val F1: 0.9872, Test F1: 0.9926\n",
            "Epoch: 65, Loss: 0.0074,    Val F1: 0.9873, Test F1: 0.9927\n",
            "Epoch: 66, Loss: 0.0072,    Val F1: 0.9873, Test F1: 0.9926\n",
            "Epoch: 67, Loss: 0.0073,    Val F1: 0.9874, Test F1: 0.9926\n",
            "Epoch: 68, Loss: 0.0072,    Val F1: 0.9873, Test F1: 0.9926\n",
            "Epoch: 69, Loss: 0.0072,    Val F1: 0.9872, Test F1: 0.9927\n",
            "Epoch: 70, Loss: 0.0077,    Val F1: 0.9872, Test F1: 0.9926\n",
            "Epoch: 71, Loss: 0.0072,    Val F1: 0.9872, Test F1: 0.9927\n",
            "Epoch: 72, Loss: 0.0076,    Val F1: 0.9871, Test F1: 0.9927\n",
            "Epoch: 73, Loss: 0.0074,    Val F1: 0.9872, Test F1: 0.9927\n",
            "Epoch: 74, Loss: 0.0075,    Val F1: 0.9874, Test F1: 0.9928\n",
            "Epoch: 75, Loss: 0.0069,    Val F1: 0.9874, Test F1: 0.9927\n",
            "Epoch: 76, Loss: 0.0072,    Val F1: 0.9872, Test F1: 0.9926\n",
            "Epoch: 77, Loss: 0.0072,    Val F1: 0.9871, Test F1: 0.9925\n",
            "Epoch: 78, Loss: 0.0070,    Val F1: 0.9872, Test F1: 0.9928\n",
            "Epoch: 79, Loss: 0.0074,    Val F1: 0.9873, Test F1: 0.9928\n",
            "Epoch: 80, Loss: 0.0070,    Val F1: 0.9874, Test F1: 0.9928\n",
            "Epoch: 81, Loss: 0.0078,    Val F1: 0.9872, Test F1: 0.9926\n",
            "Epoch: 82, Loss: 0.0072,    Val F1: 0.9871, Test F1: 0.9926\n",
            "Epoch: 83, Loss: 0.0070,    Val F1: 0.9872, Test F1: 0.9927\n",
            "Epoch: 84, Loss: 0.0068,    Val F1: 0.9874, Test F1: 0.9927\n",
            "Epoch: 85, Loss: 0.0068,    Val F1: 0.9874, Test F1: 0.9926\n",
            "Epoch: 86, Loss: 0.0065,    Val F1: 0.9875, Test F1: 0.9927\n",
            "Epoch: 87, Loss: 0.0064,    Val F1: 0.9874, Test F1: 0.9927\n",
            "Epoch: 88, Loss: 0.0071,    Val F1: 0.9871, Test F1: 0.9926\n",
            "Epoch: 89, Loss: 0.0071,    Val F1: 0.9874, Test F1: 0.9929\n",
            "Epoch: 90, Loss: 0.0069,    Val F1: 0.9873, Test F1: 0.9928\n",
            "Epoch: 91, Loss: 0.0071,    Val F1: 0.9873, Test F1: 0.9927\n",
            "Epoch: 92, Loss: 0.0077,    Val F1: 0.9872, Test F1: 0.9927\n",
            "Epoch: 93, Loss: 0.0071,    Val F1: 0.9872, Test F1: 0.9926\n",
            "Epoch: 94, Loss: 0.0079,    Val F1: 0.9874, Test F1: 0.9926\n",
            "Epoch: 95, Loss: 0.0072,    Val F1: 0.9875, Test F1: 0.9928\n",
            "Epoch: 96, Loss: 0.0070,    Val F1: 0.9874, Test F1: 0.9927\n",
            "Epoch: 97, Loss: 0.0067,    Val F1: 0.9875, Test F1: 0.9929\n",
            "Epoch: 98, Loss: 0.0066,    Val F1: 0.9874, Test F1: 0.9927\n",
            "Epoch: 99, Loss: 0.0069,    Val F1: 0.9875, Test F1: 0.9928\n",
            "Epoch: 100, Loss: 0.0068,    Val F1: 0.9875, Test F1: 0.9927\n",
            "Epoch: 101, Loss: 0.0066,    Val F1: 0.9875, Test F1: 0.9926\n",
            "Epoch: 102, Loss: 0.0071,    Val F1: 0.9874, Test F1: 0.9926\n",
            "Epoch: 103, Loss: 0.0072,    Val F1: 0.9876, Test F1: 0.9926\n",
            "Epoch: 104, Loss: 0.0074,    Val F1: 0.9875, Test F1: 0.9927\n",
            "Epoch: 105, Loss: 0.0072,    Val F1: 0.9875, Test F1: 0.9927\n",
            "Epoch: 106, Loss: 0.0069,    Val F1: 0.9873, Test F1: 0.9928\n",
            "Epoch: 107, Loss: 0.0068,    Val F1: 0.9875, Test F1: 0.9927\n",
            "Epoch: 108, Loss: 0.0070,    Val F1: 0.9876, Test F1: 0.9928\n",
            "Epoch: 109, Loss: 0.0075,    Val F1: 0.9877, Test F1: 0.9927\n",
            "Epoch: 110, Loss: 0.0073,    Val F1: 0.9877, Test F1: 0.9928\n",
            "Epoch: 111, Loss: 0.0070,    Val F1: 0.9876, Test F1: 0.9928\n",
            "Epoch: 112, Loss: 0.0070,    Val F1: 0.9877, Test F1: 0.9929\n",
            "Epoch: 113, Loss: 0.0070,    Val F1: 0.9876, Test F1: 0.9927\n",
            "Epoch: 114, Loss: 0.0069,    Val F1: 0.9876, Test F1: 0.9928\n",
            "Epoch: 115, Loss: 0.0075,    Val F1: 0.9875, Test F1: 0.9928\n",
            "Epoch: 116, Loss: 0.0074,    Val F1: 0.9876, Test F1: 0.9928\n",
            "Epoch: 117, Loss: 0.0070,    Val F1: 0.9874, Test F1: 0.9927\n",
            "Epoch: 118, Loss: 0.0070,    Val F1: 0.9874, Test F1: 0.9928\n",
            "Epoch: 119, Loss: 0.0070,    Val F1: 0.9875, Test F1: 0.9928\n",
            "Epoch: 120, Loss: 0.0074,    Val F1: 0.9874, Test F1: 0.9928\n",
            "Epoch: 121, Loss: 0.0071,    Val F1: 0.9877, Test F1: 0.9929\n",
            "Epoch: 122, Loss: 0.0067,    Val F1: 0.9874, Test F1: 0.9928\n",
            "Epoch: 123, Loss: 0.0071,    Val F1: 0.9873, Test F1: 0.9927\n",
            "Epoch: 124, Loss: 0.0074,    Val F1: 0.9874, Test F1: 0.9927\n",
            "Epoch: 125, Loss: 0.0070,    Val F1: 0.9874, Test F1: 0.9926\n",
            "Epoch: 126, Loss: 0.0069,    Val F1: 0.9876, Test F1: 0.9927\n",
            "Epoch: 127, Loss: 0.0070,    Val F1: 0.9873, Test F1: 0.9926\n",
            "Epoch: 128, Loss: 0.0071,    Val F1: 0.9873, Test F1: 0.9927\n",
            "Epoch: 129, Loss: 0.0072,    Val F1: 0.9874, Test F1: 0.9927\n",
            "Epoch: 130, Loss: 0.0066,    Val F1: 0.9875, Test F1: 0.9926\n",
            "Epoch: 131, Loss: 0.0068,    Val F1: 0.9875, Test F1: 0.9927\n",
            "Epoch: 132, Loss: 0.0068,    Val F1: 0.9873, Test F1: 0.9926\n",
            "Epoch: 133, Loss: 0.0068,    Val F1: 0.9874, Test F1: 0.9927\n",
            "Epoch: 134, Loss: 0.0071,    Val F1: 0.9874, Test F1: 0.9927\n",
            "Epoch: 135, Loss: 0.0069,    Val F1: 0.9874, Test F1: 0.9926\n",
            "Epoch: 136, Loss: 0.0066,    Val F1: 0.9876, Test F1: 0.9926\n",
            "Epoch: 137, Loss: 0.0067,    Val F1: 0.9874, Test F1: 0.9926\n",
            "Epoch: 138, Loss: 0.0066,    Val F1: 0.9872, Test F1: 0.9926\n",
            "Epoch: 139, Loss: 0.0066,    Val F1: 0.9872, Test F1: 0.9924\n",
            "Epoch: 140, Loss: 0.0074,    Val F1: 0.9875, Test F1: 0.9929\n",
            "Epoch: 141, Loss: 0.0066,    Val F1: 0.9874, Test F1: 0.9927\n",
            "Epoch: 142, Loss: 0.0067,    Val F1: 0.9875, Test F1: 0.9926\n",
            "Epoch: 143, Loss: 0.0069,    Val F1: 0.9873, Test F1: 0.9928\n",
            "Epoch: 144, Loss: 0.0070,    Val F1: 0.9875, Test F1: 0.9926\n",
            "Epoch: 145, Loss: 0.0068,    Val F1: 0.9876, Test F1: 0.9925\n",
            "Epoch: 146, Loss: 0.0064,    Val F1: 0.9876, Test F1: 0.9927\n",
            "Epoch: 147, Loss: 0.0071,    Val F1: 0.9874, Test F1: 0.9927\n",
            "Epoch: 148, Loss: 0.0069,    Val F1: 0.9874, Test F1: 0.9926\n",
            "Epoch: 149, Loss: 0.0067,    Val F1: 0.9874, Test F1: 0.9926\n",
            "Epoch: 150, Loss: 0.0066,    Val F1: 0.9874, Test F1: 0.9928\n",
            "Epoch: 151, Loss: 0.0070,    Val F1: 0.9874, Test F1: 0.9927\n",
            "Epoch: 152, Loss: 0.0064,    Val F1: 0.9876, Test F1: 0.9927\n",
            "Epoch: 153, Loss: 0.0068,    Val F1: 0.9878, Test F1: 0.9928\n",
            "Epoch: 154, Loss: 0.0062,    Val F1: 0.9878, Test F1: 0.9928\n",
            "Epoch: 155, Loss: 0.0060,    Val F1: 0.9877, Test F1: 0.9928\n",
            "Epoch: 156, Loss: 0.0064,    Val F1: 0.9877, Test F1: 0.9928\n",
            "Epoch: 157, Loss: 0.0063,    Val F1: 0.9875, Test F1: 0.9928\n",
            "Epoch: 158, Loss: 0.0064,    Val F1: 0.9876, Test F1: 0.9928\n",
            "Epoch: 159, Loss: 0.0063,    Val F1: 0.9879, Test F1: 0.9930\n",
            "Epoch: 160, Loss: 0.0063,    Val F1: 0.9876, Test F1: 0.9927\n",
            "Epoch: 161, Loss: 0.0064,    Val F1: 0.9876, Test F1: 0.9926\n",
            "Epoch: 162, Loss: 0.0062,    Val F1: 0.9878, Test F1: 0.9928\n",
            "Epoch: 163, Loss: 0.0066,    Val F1: 0.9877, Test F1: 0.9928\n",
            "Epoch: 164, Loss: 0.0061,    Val F1: 0.9876, Test F1: 0.9929\n",
            "Epoch: 165, Loss: 0.0063,    Val F1: 0.9875, Test F1: 0.9927\n",
            "Epoch: 166, Loss: 0.0063,    Val F1: 0.9877, Test F1: 0.9927\n",
            "Epoch: 167, Loss: 0.0063,    Val F1: 0.9875, Test F1: 0.9927\n",
            "Epoch: 168, Loss: 0.0065,    Val F1: 0.9877, Test F1: 0.9928\n",
            "Epoch: 169, Loss: 0.0063,    Val F1: 0.9875, Test F1: 0.9927\n",
            "Epoch: 170, Loss: 0.0068,    Val F1: 0.9875, Test F1: 0.9927\n",
            "Epoch: 171, Loss: 0.0070,    Val F1: 0.9876, Test F1: 0.9928\n",
            "Epoch: 172, Loss: 0.0067,    Val F1: 0.9876, Test F1: 0.9928\n",
            "Epoch: 173, Loss: 0.0061,    Val F1: 0.9876, Test F1: 0.9928\n",
            "Epoch: 174, Loss: 0.0062,    Val F1: 0.9877, Test F1: 0.9928\n",
            "Epoch: 175, Loss: 0.0071,    Val F1: 0.9877, Test F1: 0.9928\n",
            "Epoch: 176, Loss: 0.0067,    Val F1: 0.9878, Test F1: 0.9928\n",
            "Epoch: 177, Loss: 0.0063,    Val F1: 0.9881, Test F1: 0.9928\n",
            "Epoch: 178, Loss: 0.0062,    Val F1: 0.9879, Test F1: 0.9927\n",
            "Epoch: 179, Loss: 0.0065,    Val F1: 0.9880, Test F1: 0.9927\n",
            "Epoch: 180, Loss: 0.0061,    Val F1: 0.9879, Test F1: 0.9928\n",
            "Epoch: 181, Loss: 0.0062,    Val F1: 0.9878, Test F1: 0.9929\n",
            "Epoch: 182, Loss: 0.0061,    Val F1: 0.9879, Test F1: 0.9928\n",
            "Epoch: 183, Loss: 0.0060,    Val F1: 0.9876, Test F1: 0.9925\n",
            "Epoch: 184, Loss: 0.0068,    Val F1: 0.9879, Test F1: 0.9928\n",
            "Epoch: 185, Loss: 0.0062,    Val F1: 0.9878, Test F1: 0.9928\n",
            "Epoch: 186, Loss: 0.0066,    Val F1: 0.9878, Test F1: 0.9927\n",
            "Epoch: 187, Loss: 0.0062,    Val F1: 0.9879, Test F1: 0.9927\n",
            "Epoch: 188, Loss: 0.0065,    Val F1: 0.9878, Test F1: 0.9927\n",
            "Epoch: 189, Loss: 0.0066,    Val F1: 0.9878, Test F1: 0.9929\n",
            "Epoch: 190, Loss: 0.0065,    Val F1: 0.9877, Test F1: 0.9928\n",
            "Epoch: 191, Loss: 0.0065,    Val F1: 0.9877, Test F1: 0.9929\n",
            "Epoch: 192, Loss: 0.0068,    Val F1: 0.9879, Test F1: 0.9928\n",
            "Epoch: 193, Loss: 0.0062,    Val F1: 0.9877, Test F1: 0.9927\n",
            "Epoch: 194, Loss: 0.0062,    Val F1: 0.9876, Test F1: 0.9926\n",
            "Epoch: 195, Loss: 0.0064,    Val F1: 0.9878, Test F1: 0.9929\n",
            "Epoch: 196, Loss: 0.0064,    Val F1: 0.9876, Test F1: 0.9927\n",
            "Epoch: 197, Loss: 0.0063,    Val F1: 0.9876, Test F1: 0.9926\n",
            "Epoch: 198, Loss: 0.0071,    Val F1: 0.9877, Test F1: 0.9926\n",
            "Epoch: 199, Loss: 0.0063,    Val F1: 0.9880, Test F1: 0.9929\n",
            "Epoch: 200, Loss: 0.0062,    Val F1: 0.9878, Test F1: 0.9928\n",
            "Epoch: 201, Loss: 0.0062,    Val F1: 0.9878, Test F1: 0.9927\n",
            "Epoch: 202, Loss: 0.0070,    Val F1: 0.9879, Test F1: 0.9928\n",
            "Epoch: 203, Loss: 0.0063,    Val F1: 0.9876, Test F1: 0.9927\n",
            "Epoch: 204, Loss: 0.0066,    Val F1: 0.9876, Test F1: 0.9928\n",
            "Epoch: 205, Loss: 0.0062,    Val F1: 0.9875, Test F1: 0.9928\n",
            "Epoch: 206, Loss: 0.0061,    Val F1: 0.9877, Test F1: 0.9928\n",
            "Epoch: 207, Loss: 0.0066,    Val F1: 0.9878, Test F1: 0.9929\n",
            "Epoch: 208, Loss: 0.0061,    Val F1: 0.9878, Test F1: 0.9928\n",
            "Epoch: 209, Loss: 0.0063,    Val F1: 0.9877, Test F1: 0.9928\n",
            "Epoch: 210, Loss: 0.0067,    Val F1: 0.9879, Test F1: 0.9928\n",
            "Epoch: 211, Loss: 0.0064,    Val F1: 0.9878, Test F1: 0.9927\n",
            "Epoch: 212, Loss: 0.0060,    Val F1: 0.9878, Test F1: 0.9927\n",
            "Epoch: 213, Loss: 0.0061,    Val F1: 0.9879, Test F1: 0.9927\n",
            "Epoch: 214, Loss: 0.0060,    Val F1: 0.9876, Test F1: 0.9927\n",
            "Epoch: 215, Loss: 0.0058,    Val F1: 0.9878, Test F1: 0.9927\n",
            "Epoch: 216, Loss: 0.0061,    Val F1: 0.9879, Test F1: 0.9927\n",
            "Epoch: 217, Loss: 0.0064,    Val F1: 0.9878, Test F1: 0.9927\n",
            "Epoch: 218, Loss: 0.0064,    Val F1: 0.9878, Test F1: 0.9927\n",
            "Epoch: 219, Loss: 0.0062,    Val F1: 0.9878, Test F1: 0.9927\n",
            "Epoch: 220, Loss: 0.0061,    Val F1: 0.9878, Test F1: 0.9928\n",
            "Epoch: 221, Loss: 0.0067,    Val F1: 0.9878, Test F1: 0.9927\n",
            "Epoch: 222, Loss: 0.0063,    Val F1: 0.9879, Test F1: 0.9926\n",
            "Epoch: 223, Loss: 0.0064,    Val F1: 0.9875, Test F1: 0.9926\n",
            "Epoch: 224, Loss: 0.0060,    Val F1: 0.9877, Test F1: 0.9927\n",
            "Epoch: 225, Loss: 0.0063,    Val F1: 0.9876, Test F1: 0.9926\n",
            "Epoch: 226, Loss: 0.0063,    Val F1: 0.9878, Test F1: 0.9927\n",
            "Epoch: 227, Loss: 0.0060,    Val F1: 0.9877, Test F1: 0.9927\n",
            "Epoch: 228, Loss: 0.0060,    Val F1: 0.9878, Test F1: 0.9926\n",
            "Epoch: 229, Loss: 0.0061,    Val F1: 0.9878, Test F1: 0.9926\n",
            "Epoch: 230, Loss: 0.0058,    Val F1: 0.9878, Test F1: 0.9926\n",
            "Epoch: 231, Loss: 0.0061,    Val F1: 0.9880, Test F1: 0.9927\n",
            "Epoch: 232, Loss: 0.0060,    Val F1: 0.9879, Test F1: 0.9928\n",
            "Epoch: 233, Loss: 0.0059,    Val F1: 0.9877, Test F1: 0.9926\n",
            "Epoch: 234, Loss: 0.0060,    Val F1: 0.9877, Test F1: 0.9928\n",
            "Epoch: 235, Loss: 0.0066,    Val F1: 0.9876, Test F1: 0.9928\n",
            "Epoch: 236, Loss: 0.0059,    Val F1: 0.9876, Test F1: 0.9928\n",
            "Epoch: 237, Loss: 0.0060,    Val F1: 0.9876, Test F1: 0.9928\n",
            "Epoch: 238, Loss: 0.0062,    Val F1: 0.9874, Test F1: 0.9927\n",
            "Epoch: 239, Loss: 0.0059,    Val F1: 0.9877, Test F1: 0.9929\n",
            "Epoch: 240, Loss: 0.0061,    Val F1: 0.9876, Test F1: 0.9930\n",
            "Epoch: 241, Loss: 0.0060,    Val F1: 0.9875, Test F1: 0.9928\n",
            "Epoch: 242, Loss: 0.0058,    Val F1: 0.9876, Test F1: 0.9929\n",
            "Epoch: 243, Loss: 0.0064,    Val F1: 0.9877, Test F1: 0.9929\n",
            "Epoch: 244, Loss: 0.0060,    Val F1: 0.9877, Test F1: 0.9929\n",
            "Epoch: 245, Loss: 0.0058,    Val F1: 0.9878, Test F1: 0.9928\n",
            "Epoch: 246, Loss: 0.0059,    Val F1: 0.9877, Test F1: 0.9927\n",
            "Epoch: 247, Loss: 0.0060,    Val F1: 0.9879, Test F1: 0.9929\n",
            "Epoch: 248, Loss: 0.0064,    Val F1: 0.9876, Test F1: 0.9929\n",
            "Epoch: 249, Loss: 0.0060,    Val F1: 0.9878, Test F1: 0.9928\n",
            "Epoch: 250, Loss: 0.0063,    Val F1: 0.9879, Test F1: 0.9928\n",
            "Epoch: 251, Loss: 0.0058,    Val F1: 0.9877, Test F1: 0.9927\n",
            "Epoch: 252, Loss: 0.0067,    Val F1: 0.9876, Test F1: 0.9928\n",
            "Epoch: 253, Loss: 0.0063,    Val F1: 0.9877, Test F1: 0.9929\n",
            "Epoch: 254, Loss: 0.0064,    Val F1: 0.9878, Test F1: 0.9929\n",
            "Epoch: 255, Loss: 0.0060,    Val F1: 0.9877, Test F1: 0.9929\n",
            "Epoch: 256, Loss: 0.0061,    Val F1: 0.9877, Test F1: 0.9927\n",
            "Epoch: 257, Loss: 0.0057,    Val F1: 0.9877, Test F1: 0.9926\n",
            "Epoch: 258, Loss: 0.0059,    Val F1: 0.9876, Test F1: 0.9926\n",
            "Epoch: 259, Loss: 0.0065,    Val F1: 0.9878, Test F1: 0.9928\n",
            "Epoch: 260, Loss: 0.0056,    Val F1: 0.9877, Test F1: 0.9927\n",
            "Epoch: 261, Loss: 0.0063,    Val F1: 0.9876, Test F1: 0.9927\n",
            "Epoch: 262, Loss: 0.0060,    Val F1: 0.9878, Test F1: 0.9927\n",
            "Epoch: 263, Loss: 0.0060,    Val F1: 0.9877, Test F1: 0.9929\n",
            "Epoch: 264, Loss: 0.0059,    Val F1: 0.9874, Test F1: 0.9928\n",
            "Epoch: 265, Loss: 0.0058,    Val F1: 0.9875, Test F1: 0.9928\n",
            "Epoch: 266, Loss: 0.0060,    Val F1: 0.9877, Test F1: 0.9930\n",
            "Epoch: 267, Loss: 0.0059,    Val F1: 0.9878, Test F1: 0.9929\n",
            "Epoch: 268, Loss: 0.0057,    Val F1: 0.9878, Test F1: 0.9929\n",
            "Epoch: 269, Loss: 0.0063,    Val F1: 0.9878, Test F1: 0.9930\n",
            "Epoch: 270, Loss: 0.0065,    Val F1: 0.9875, Test F1: 0.9929\n",
            "Epoch: 271, Loss: 0.0061,    Val F1: 0.9878, Test F1: 0.9928\n",
            "Epoch: 272, Loss: 0.0061,    Val F1: 0.9878, Test F1: 0.9928\n",
            "Epoch: 273, Loss: 0.0058,    Val F1: 0.9878, Test F1: 0.9928\n",
            "Epoch: 274, Loss: 0.0060,    Val F1: 0.9878, Test F1: 0.9927\n",
            "Epoch: 275, Loss: 0.0058,    Val F1: 0.9879, Test F1: 0.9929\n",
            "Epoch: 276, Loss: 0.0061,    Val F1: 0.9878, Test F1: 0.9927\n",
            "Epoch: 277, Loss: 0.0058,    Val F1: 0.9878, Test F1: 0.9928\n",
            "Epoch: 278, Loss: 0.0060,    Val F1: 0.9881, Test F1: 0.9929\n",
            "Epoch: 279, Loss: 0.0062,    Val F1: 0.9878, Test F1: 0.9928\n",
            "Epoch: 280, Loss: 0.0059,    Val F1: 0.9878, Test F1: 0.9930\n",
            "Epoch: 281, Loss: 0.0061,    Val F1: 0.9876, Test F1: 0.9928\n",
            "Epoch: 282, Loss: 0.0057,    Val F1: 0.9878, Test F1: 0.9929\n",
            "Epoch: 283, Loss: 0.0060,    Val F1: 0.9876, Test F1: 0.9929\n",
            "Epoch: 284, Loss: 0.0064,    Val F1: 0.9879, Test F1: 0.9930\n",
            "Epoch: 285, Loss: 0.0058,    Val F1: 0.9877, Test F1: 0.9929\n",
            "Epoch: 286, Loss: 0.0061,    Val F1: 0.9874, Test F1: 0.9928\n",
            "Epoch: 287, Loss: 0.0060,    Val F1: 0.9876, Test F1: 0.9929\n",
            "Epoch: 288, Loss: 0.0070,    Val F1: 0.9877, Test F1: 0.9928\n",
            "Epoch: 289, Loss: 0.0064,    Val F1: 0.9875, Test F1: 0.9927\n",
            "Epoch: 290, Loss: 0.0064,    Val F1: 0.9877, Test F1: 0.9927\n",
            "Epoch: 291, Loss: 0.0064,    Val F1: 0.9876, Test F1: 0.9927\n",
            "Epoch: 292, Loss: 0.0061,    Val F1: 0.9876, Test F1: 0.9927\n",
            "Epoch: 293, Loss: 0.0063,    Val F1: 0.9876, Test F1: 0.9926\n",
            "Epoch: 294, Loss: 0.0063,    Val F1: 0.9877, Test F1: 0.9927\n",
            "Epoch: 295, Loss: 0.0062,    Val F1: 0.9878, Test F1: 0.9928\n",
            "Epoch: 296, Loss: 0.0061,    Val F1: 0.9877, Test F1: 0.9928\n",
            "Epoch: 297, Loss: 0.0060,    Val F1: 0.9877, Test F1: 0.9927\n",
            "Epoch: 298, Loss: 0.0065,    Val F1: 0.9874, Test F1: 0.9927\n",
            "Epoch: 299, Loss: 0.0061,    Val F1: 0.9876, Test F1: 0.9927\n",
            "Epoch: 300, Loss: 0.0062,    Val F1: 0.9876, Test F1: 0.9929\n",
            "Epoch: 301, Loss: 0.0063,    Val F1: 0.9877, Test F1: 0.9928\n",
            "Epoch: 302, Loss: 0.0062,    Val F1: 0.9876, Test F1: 0.9927\n",
            "Epoch: 303, Loss: 0.0072,    Val F1: 0.9876, Test F1: 0.9929\n",
            "Epoch: 304, Loss: 0.0061,    Val F1: 0.9877, Test F1: 0.9927\n",
            "Epoch: 305, Loss: 0.0068,    Val F1: 0.9873, Test F1: 0.9928\n",
            "Epoch: 306, Loss: 0.0058,    Val F1: 0.9876, Test F1: 0.9928\n",
            "Epoch: 307, Loss: 0.0063,    Val F1: 0.9877, Test F1: 0.9927\n",
            "Epoch: 308, Loss: 0.0066,    Val F1: 0.9877, Test F1: 0.9928\n",
            "Epoch: 309, Loss: 0.0056,    Val F1: 0.9878, Test F1: 0.9929\n",
            "Epoch: 310, Loss: 0.0057,    Val F1: 0.9876, Test F1: 0.9929\n",
            "Epoch: 311, Loss: 0.0057,    Val F1: 0.9879, Test F1: 0.9928\n",
            "Epoch: 312, Loss: 0.0055,    Val F1: 0.9878, Test F1: 0.9927\n",
            "Epoch: 313, Loss: 0.0054,    Val F1: 0.9878, Test F1: 0.9929\n",
            "Epoch: 314, Loss: 0.0057,    Val F1: 0.9879, Test F1: 0.9929\n",
            "Epoch: 315, Loss: 0.0064,    Val F1: 0.9877, Test F1: 0.9927\n",
            "Epoch: 316, Loss: 0.0056,    Val F1: 0.9879, Test F1: 0.9929\n",
            "Epoch: 317, Loss: 0.0059,    Val F1: 0.9878, Test F1: 0.9927\n",
            "Epoch: 318, Loss: 0.0059,    Val F1: 0.9878, Test F1: 0.9928\n",
            "Epoch: 319, Loss: 0.0056,    Val F1: 0.9877, Test F1: 0.9927\n",
            "Epoch: 320, Loss: 0.0057,    Val F1: 0.9877, Test F1: 0.9928\n",
            "Epoch: 321, Loss: 0.0056,    Val F1: 0.9877, Test F1: 0.9927\n",
            "Epoch: 322, Loss: 0.0059,    Val F1: 0.9878, Test F1: 0.9927\n",
            "Epoch: 323, Loss: 0.0064,    Val F1: 0.9878, Test F1: 0.9928\n",
            "Epoch: 324, Loss: 0.0054,    Val F1: 0.9878, Test F1: 0.9928\n",
            "Epoch: 325, Loss: 0.0058,    Val F1: 0.9879, Test F1: 0.9928\n",
            "Epoch: 326, Loss: 0.0056,    Val F1: 0.9878, Test F1: 0.9928\n",
            "Epoch: 327, Loss: 0.0056,    Val F1: 0.9878, Test F1: 0.9928\n",
            "Epoch: 328, Loss: 0.0063,    Val F1: 0.9877, Test F1: 0.9927\n",
            "Epoch: 329, Loss: 0.0066,    Val F1: 0.9876, Test F1: 0.9929\n",
            "Epoch: 330, Loss: 0.0069,    Val F1: 0.9874, Test F1: 0.9927\n",
            "Epoch: 331, Loss: 0.0059,    Val F1: 0.9877, Test F1: 0.9927\n",
            "Epoch: 332, Loss: 0.0065,    Val F1: 0.9878, Test F1: 0.9928\n",
            "Epoch: 333, Loss: 0.0068,    Val F1: 0.9876, Test F1: 0.9925\n",
            "Epoch: 334, Loss: 0.0062,    Val F1: 0.9876, Test F1: 0.9927\n",
            "Epoch: 335, Loss: 0.0063,    Val F1: 0.9875, Test F1: 0.9928\n",
            "Epoch: 336, Loss: 0.0061,    Val F1: 0.9877, Test F1: 0.9928\n",
            "Epoch: 337, Loss: 0.0056,    Val F1: 0.9879, Test F1: 0.9930\n",
            "Epoch: 338, Loss: 0.0056,    Val F1: 0.9877, Test F1: 0.9929\n",
            "Epoch: 339, Loss: 0.0058,    Val F1: 0.9876, Test F1: 0.9929\n",
            "Epoch: 340, Loss: 0.0062,    Val F1: 0.9877, Test F1: 0.9929\n",
            "Epoch: 341, Loss: 0.0063,    Val F1: 0.9876, Test F1: 0.9926\n",
            "Epoch: 342, Loss: 0.0064,    Val F1: 0.9876, Test F1: 0.9928\n",
            "Epoch: 343, Loss: 0.0063,    Val F1: 0.9873, Test F1: 0.9927\n",
            "Epoch: 344, Loss: 0.0056,    Val F1: 0.9875, Test F1: 0.9927\n",
            "Epoch: 345, Loss: 0.0054,    Val F1: 0.9876, Test F1: 0.9928\n",
            "Epoch: 346, Loss: 0.0058,    Val F1: 0.9877, Test F1: 0.9928\n",
            "Epoch: 347, Loss: 0.0056,    Val F1: 0.9875, Test F1: 0.9928\n",
            "Epoch: 348, Loss: 0.0053,    Val F1: 0.9877, Test F1: 0.9928\n",
            "Epoch: 349, Loss: 0.0054,    Val F1: 0.9876, Test F1: 0.9928\n",
            "Epoch: 350, Loss: 0.0055,    Val F1: 0.9878, Test F1: 0.9929\n",
            "Epoch: 351, Loss: 0.0058,    Val F1: 0.9879, Test F1: 0.9929\n",
            "Epoch: 352, Loss: 0.0054,    Val F1: 0.9877, Test F1: 0.9930\n",
            "Epoch: 353, Loss: 0.0055,    Val F1: 0.9878, Test F1: 0.9931\n",
            "Epoch: 354, Loss: 0.0052,    Val F1: 0.9873, Test F1: 0.9929\n",
            "Epoch: 355, Loss: 0.0055,    Val F1: 0.9875, Test F1: 0.9930\n",
            "Epoch: 356, Loss: 0.0058,    Val F1: 0.9876, Test F1: 0.9928\n",
            "Epoch: 357, Loss: 0.0057,    Val F1: 0.9875, Test F1: 0.9929\n",
            "Epoch: 358, Loss: 0.0056,    Val F1: 0.9873, Test F1: 0.9928\n",
            "Epoch: 359, Loss: 0.0058,    Val F1: 0.9874, Test F1: 0.9927\n",
            "Epoch: 360, Loss: 0.0059,    Val F1: 0.9874, Test F1: 0.9928\n",
            "Epoch: 361, Loss: 0.0055,    Val F1: 0.9875, Test F1: 0.9928\n",
            "Epoch: 362, Loss: 0.0057,    Val F1: 0.9874, Test F1: 0.9928\n",
            "Epoch: 363, Loss: 0.0059,    Val F1: 0.9876, Test F1: 0.9929\n",
            "Epoch: 364, Loss: 0.0055,    Val F1: 0.9877, Test F1: 0.9930\n",
            "Epoch: 365, Loss: 0.0058,    Val F1: 0.9874, Test F1: 0.9928\n",
            "Epoch: 366, Loss: 0.0062,    Val F1: 0.9876, Test F1: 0.9929\n",
            "Epoch: 367, Loss: 0.0057,    Val F1: 0.9875, Test F1: 0.9927\n",
            "Epoch: 368, Loss: 0.0059,    Val F1: 0.9875, Test F1: 0.9928\n",
            "Epoch: 369, Loss: 0.0057,    Val F1: 0.9875, Test F1: 0.9928\n",
            "Epoch: 370, Loss: 0.0054,    Val F1: 0.9875, Test F1: 0.9927\n",
            "Epoch: 371, Loss: 0.0063,    Val F1: 0.9875, Test F1: 0.9927\n",
            "Epoch: 372, Loss: 0.0055,    Val F1: 0.9874, Test F1: 0.9927\n",
            "Epoch: 373, Loss: 0.0054,    Val F1: 0.9877, Test F1: 0.9928\n",
            "Epoch: 374, Loss: 0.0052,    Val F1: 0.9878, Test F1: 0.9928\n",
            "Epoch: 375, Loss: 0.0055,    Val F1: 0.9875, Test F1: 0.9928\n",
            "Epoch: 376, Loss: 0.0055,    Val F1: 0.9877, Test F1: 0.9928\n",
            "Epoch: 377, Loss: 0.0062,    Val F1: 0.9875, Test F1: 0.9924\n",
            "Epoch: 378, Loss: 0.0065,    Val F1: 0.9873, Test F1: 0.9926\n",
            "Epoch: 379, Loss: 0.0069,    Val F1: 0.9876, Test F1: 0.9927\n",
            "Epoch: 380, Loss: 0.0059,    Val F1: 0.9876, Test F1: 0.9927\n",
            "Epoch: 381, Loss: 0.0061,    Val F1: 0.9877, Test F1: 0.9928\n",
            "Epoch: 382, Loss: 0.0058,    Val F1: 0.9878, Test F1: 0.9927\n",
            "Epoch: 383, Loss: 0.0056,    Val F1: 0.9878, Test F1: 0.9928\n",
            "Epoch: 384, Loss: 0.0054,    Val F1: 0.9878, Test F1: 0.9929\n",
            "Epoch: 385, Loss: 0.0055,    Val F1: 0.9877, Test F1: 0.9928\n",
            "Epoch: 386, Loss: 0.0055,    Val F1: 0.9879, Test F1: 0.9928\n",
            "Epoch: 387, Loss: 0.0053,    Val F1: 0.9877, Test F1: 0.9928\n",
            "Epoch: 388, Loss: 0.0052,    Val F1: 0.9878, Test F1: 0.9929\n",
            "Epoch: 389, Loss: 0.0052,    Val F1: 0.9878, Test F1: 0.9928\n",
            "Epoch: 390, Loss: 0.0056,    Val F1: 0.9879, Test F1: 0.9929\n",
            "Epoch: 391, Loss: 0.0055,    Val F1: 0.9878, Test F1: 0.9928\n",
            "Epoch: 392, Loss: 0.0053,    Val F1: 0.9878, Test F1: 0.9927\n",
            "Epoch: 393, Loss: 0.0054,    Val F1: 0.9880, Test F1: 0.9929\n",
            "Epoch: 394, Loss: 0.0064,    Val F1: 0.9879, Test F1: 0.9928\n",
            "Epoch: 395, Loss: 0.0055,    Val F1: 0.9879, Test F1: 0.9930\n",
            "Epoch: 396, Loss: 0.0058,    Val F1: 0.9878, Test F1: 0.9928\n",
            "Epoch: 397, Loss: 0.0056,    Val F1: 0.9878, Test F1: 0.9929\n",
            "Epoch: 398, Loss: 0.0055,    Val F1: 0.9877, Test F1: 0.9929\n",
            "Epoch: 399, Loss: 0.0058,    Val F1: 0.9875, Test F1: 0.9928\n",
            "Epoch: 400, Loss: 0.0056,    Val F1: 0.9880, Test F1: 0.9930\n",
            "Epoch: 401, Loss: 0.0060,    Val F1: 0.9876, Test F1: 0.9927\n",
            "Epoch: 402, Loss: 0.0059,    Val F1: 0.9879, Test F1: 0.9928\n",
            "Epoch: 403, Loss: 0.0056,    Val F1: 0.9878, Test F1: 0.9928\n",
            "Epoch: 404, Loss: 0.0055,    Val F1: 0.9878, Test F1: 0.9927\n",
            "Epoch: 405, Loss: 0.0052,    Val F1: 0.9877, Test F1: 0.9928\n",
            "Epoch: 406, Loss: 0.0054,    Val F1: 0.9879, Test F1: 0.9927\n",
            "Epoch: 407, Loss: 0.0055,    Val F1: 0.9880, Test F1: 0.9929\n",
            "Epoch: 408, Loss: 0.0054,    Val F1: 0.9879, Test F1: 0.9929\n",
            "Epoch: 409, Loss: 0.0054,    Val F1: 0.9878, Test F1: 0.9930\n",
            "Epoch: 410, Loss: 0.0055,    Val F1: 0.9880, Test F1: 0.9930\n",
            "Epoch: 411, Loss: 0.0053,    Val F1: 0.9881, Test F1: 0.9929\n",
            "Epoch: 412, Loss: 0.0053,    Val F1: 0.9881, Test F1: 0.9929\n",
            "Epoch: 413, Loss: 0.0053,    Val F1: 0.9880, Test F1: 0.9930\n",
            "Epoch: 414, Loss: 0.0051,    Val F1: 0.9880, Test F1: 0.9928\n",
            "Epoch: 415, Loss: 0.0050,    Val F1: 0.9878, Test F1: 0.9928\n",
            "Epoch: 416, Loss: 0.0057,    Val F1: 0.9879, Test F1: 0.9928\n",
            "Epoch: 417, Loss: 0.0054,    Val F1: 0.9877, Test F1: 0.9926\n",
            "Epoch: 418, Loss: 0.0053,    Val F1: 0.9875, Test F1: 0.9927\n",
            "Epoch: 419, Loss: 0.0053,    Val F1: 0.9877, Test F1: 0.9928\n",
            "Epoch: 420, Loss: 0.0059,    Val F1: 0.9875, Test F1: 0.9928\n",
            "Epoch: 421, Loss: 0.0059,    Val F1: 0.9879, Test F1: 0.9929\n",
            "Epoch: 422, Loss: 0.0058,    Val F1: 0.9875, Test F1: 0.9928\n",
            "Epoch: 423, Loss: 0.0059,    Val F1: 0.9876, Test F1: 0.9928\n",
            "Epoch: 424, Loss: 0.0058,    Val F1: 0.9878, Test F1: 0.9929\n",
            "Epoch: 425, Loss: 0.0054,    Val F1: 0.9879, Test F1: 0.9928\n",
            "Epoch: 426, Loss: 0.0055,    Val F1: 0.9879, Test F1: 0.9929\n",
            "Epoch: 427, Loss: 0.0054,    Val F1: 0.9881, Test F1: 0.9930\n",
            "Epoch: 428, Loss: 0.0054,    Val F1: 0.9880, Test F1: 0.9927\n",
            "Epoch: 429, Loss: 0.0057,    Val F1: 0.9875, Test F1: 0.9926\n",
            "Epoch: 430, Loss: 0.0058,    Val F1: 0.9879, Test F1: 0.9928\n",
            "Epoch: 431, Loss: 0.0059,    Val F1: 0.9878, Test F1: 0.9928\n",
            "Epoch: 432, Loss: 0.0058,    Val F1: 0.9876, Test F1: 0.9928\n",
            "Epoch: 433, Loss: 0.0055,    Val F1: 0.9877, Test F1: 0.9928\n",
            "Epoch: 434, Loss: 0.0056,    Val F1: 0.9877, Test F1: 0.9929\n",
            "Epoch: 435, Loss: 0.0054,    Val F1: 0.9879, Test F1: 0.9929\n",
            "Epoch: 436, Loss: 0.0054,    Val F1: 0.9879, Test F1: 0.9929\n",
            "Epoch: 437, Loss: 0.0053,    Val F1: 0.9878, Test F1: 0.9927\n",
            "Epoch: 438, Loss: 0.0061,    Val F1: 0.9880, Test F1: 0.9929\n",
            "Epoch: 439, Loss: 0.0056,    Val F1: 0.9880, Test F1: 0.9929\n",
            "Epoch: 440, Loss: 0.0056,    Val F1: 0.9880, Test F1: 0.9929\n",
            "Epoch: 441, Loss: 0.0053,    Val F1: 0.9876, Test F1: 0.9927\n",
            "Epoch: 442, Loss: 0.0062,    Val F1: 0.9877, Test F1: 0.9928\n",
            "Epoch: 443, Loss: 0.0055,    Val F1: 0.9881, Test F1: 0.9928\n",
            "Epoch: 444, Loss: 0.0051,    Val F1: 0.9880, Test F1: 0.9929\n",
            "Epoch: 445, Loss: 0.0051,    Val F1: 0.9880, Test F1: 0.9929\n",
            "Epoch: 446, Loss: 0.0052,    Val F1: 0.9881, Test F1: 0.9929\n",
            "Epoch: 447, Loss: 0.0053,    Val F1: 0.9882, Test F1: 0.9928\n",
            "Epoch: 448, Loss: 0.0052,    Val F1: 0.9879, Test F1: 0.9929\n",
            "Epoch: 449, Loss: 0.0053,    Val F1: 0.9881, Test F1: 0.9930\n",
            "Epoch: 450, Loss: 0.0055,    Val F1: 0.9877, Test F1: 0.9928\n",
            "Epoch: 451, Loss: 0.0051,    Val F1: 0.9878, Test F1: 0.9929\n",
            "Epoch: 452, Loss: 0.0051,    Val F1: 0.9878, Test F1: 0.9929\n",
            "Epoch: 453, Loss: 0.0049,    Val F1: 0.9881, Test F1: 0.9929\n",
            "Epoch: 454, Loss: 0.0049,    Val F1: 0.9881, Test F1: 0.9929\n",
            "Epoch: 455, Loss: 0.0048,    Val F1: 0.9879, Test F1: 0.9929\n",
            "Epoch: 456, Loss: 0.0049,    Val F1: 0.9880, Test F1: 0.9928\n",
            "Epoch: 457, Loss: 0.0050,    Val F1: 0.9878, Test F1: 0.9929\n",
            "Epoch: 458, Loss: 0.0051,    Val F1: 0.9876, Test F1: 0.9928\n",
            "Epoch: 459, Loss: 0.0060,    Val F1: 0.9877, Test F1: 0.9928\n",
            "Epoch: 460, Loss: 0.0061,    Val F1: 0.9879, Test F1: 0.9928\n",
            "Epoch: 461, Loss: 0.0055,    Val F1: 0.9878, Test F1: 0.9927\n",
            "Epoch: 462, Loss: 0.0051,    Val F1: 0.9879, Test F1: 0.9930\n",
            "Epoch: 463, Loss: 0.0052,    Val F1: 0.9880, Test F1: 0.9929\n",
            "Epoch: 464, Loss: 0.0054,    Val F1: 0.9877, Test F1: 0.9928\n",
            "Epoch: 465, Loss: 0.0050,    Val F1: 0.9878, Test F1: 0.9928\n",
            "Epoch: 466, Loss: 0.0050,    Val F1: 0.9879, Test F1: 0.9928\n",
            "Epoch: 467, Loss: 0.0048,    Val F1: 0.9879, Test F1: 0.9929\n",
            "Epoch: 468, Loss: 0.0052,    Val F1: 0.9877, Test F1: 0.9928\n",
            "Epoch: 469, Loss: 0.0050,    Val F1: 0.9878, Test F1: 0.9928\n",
            "Epoch: 470, Loss: 0.0048,    Val F1: 0.9878, Test F1: 0.9928\n",
            "Epoch: 471, Loss: 0.0051,    Val F1: 0.9878, Test F1: 0.9927\n",
            "Epoch: 472, Loss: 0.0059,    Val F1: 0.9878, Test F1: 0.9928\n",
            "Epoch: 473, Loss: 0.0056,    Val F1: 0.9878, Test F1: 0.9928\n",
            "Epoch: 474, Loss: 0.0052,    Val F1: 0.9877, Test F1: 0.9929\n",
            "Epoch: 475, Loss: 0.0050,    Val F1: 0.9877, Test F1: 0.9927\n",
            "Epoch: 476, Loss: 0.0060,    Val F1: 0.9880, Test F1: 0.9928\n",
            "Epoch: 477, Loss: 0.0058,    Val F1: 0.9878, Test F1: 0.9930\n",
            "Epoch: 478, Loss: 0.0057,    Val F1: 0.9880, Test F1: 0.9929\n",
            "Epoch: 479, Loss: 0.0054,    Val F1: 0.9879, Test F1: 0.9928\n",
            "Epoch: 480, Loss: 0.0050,    Val F1: 0.9878, Test F1: 0.9928\n",
            "Epoch: 481, Loss: 0.0050,    Val F1: 0.9880, Test F1: 0.9929\n",
            "Epoch: 482, Loss: 0.0054,    Val F1: 0.9880, Test F1: 0.9931\n",
            "Epoch: 483, Loss: 0.0053,    Val F1: 0.9882, Test F1: 0.9929\n",
            "Epoch: 484, Loss: 0.0052,    Val F1: 0.9879, Test F1: 0.9928\n",
            "Epoch: 485, Loss: 0.0054,    Val F1: 0.9879, Test F1: 0.9928\n",
            "Epoch: 486, Loss: 0.0053,    Val F1: 0.9878, Test F1: 0.9928\n",
            "Epoch: 487, Loss: 0.0056,    Val F1: 0.9878, Test F1: 0.9928\n",
            "Epoch: 488, Loss: 0.0060,    Val F1: 0.9878, Test F1: 0.9929\n",
            "Epoch: 489, Loss: 0.0055,    Val F1: 0.9878, Test F1: 0.9929\n",
            "Epoch: 490, Loss: 0.0060,    Val F1: 0.9878, Test F1: 0.9929\n",
            "Epoch: 491, Loss: 0.0052,    Val F1: 0.9877, Test F1: 0.9929\n",
            "Epoch: 492, Loss: 0.0060,    Val F1: 0.9877, Test F1: 0.9926\n",
            "Epoch: 493, Loss: 0.0058,    Val F1: 0.9876, Test F1: 0.9929\n",
            "Epoch: 494, Loss: 0.0056,    Val F1: 0.9876, Test F1: 0.9926\n",
            "Epoch: 495, Loss: 0.0058,    Val F1: 0.9877, Test F1: 0.9928\n",
            "Epoch: 496, Loss: 0.0055,    Val F1: 0.9875, Test F1: 0.9930\n",
            "Epoch: 497, Loss: 0.0054,    Val F1: 0.9877, Test F1: 0.9929\n",
            "Epoch: 498, Loss: 0.0051,    Val F1: 0.9877, Test F1: 0.9929\n",
            "Epoch: 499, Loss: 0.0055,    Val F1: 0.9877, Test F1: 0.9928\n",
            "Epoch: 500, Loss: 0.0061,    Val F1: 0.9875, Test F1: 0.9928\n"
          ]
        }
      ]
    }
  ]
}